{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 Part 1: Is there any label leakage? \n",
    "\n",
    "- dataset label was changed to be from a uniform binary distribution. \n",
    "- strategy was fixed to: ClusterBasedWCSelector_201\n",
    "- once the strategy selects the next iteration, it is added to the training data with the TRUE labels. \n",
    "- this was done to check if the strategy selects a different set of cpds when compared to the true label. It should not, since the strategy should be label-agnostic to the cpds in the unlabeled pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_0. Index equality: True. Label equality: True\n",
      "Orig sum: 1.0. Scrambled sum: 1.0.\n",
      "iter_1. Index equality: True. Label equality: False\n",
      "Orig sum: 35.0. Scrambled sum: 47.0.\n",
      "iter_2. Index equality: True. Label equality: False\n",
      "Orig sum: 77.0. Scrambled sum: 100.0.\n",
      "iter_3. Index equality: True. Label equality: False\n",
      "Orig sum: 90.0. Scrambled sum: 153.0.\n",
      "iter_4. Index equality: True. Label equality: False\n",
      "Orig sum: 110.0. Scrambled sum: 203.0.\n",
      "iter_5. Index equality: True. Label equality: False\n",
      "Orig sum: 126.0. Scrambled sum: 248.0.\n",
      "iter_6. Index equality: True. Label equality: False\n",
      "Orig sum: 137.0. Scrambled sum: 298.0.\n",
      "Orig Total Actives: 487.0. Scrambled Total Actives:200353\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "col_name = 'Index ID'\n",
    "task_name = 'pcba-aid624173'\n",
    "\n",
    "df1 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96/unlabeled_*.csv')])\n",
    "df2 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96_scrambled/unlabeled_*.csv')])\n",
    "\n",
    "orig_total_actives = df1[task_name].sum()\n",
    "scrambled_total_actives = df2[task_name].sum()\n",
    "\n",
    "del df1, df2\n",
    "\n",
    "orig_dir = '../params_results_exp_2/original/1179/batch_size_96/training_data/iter_{}.csv'\n",
    "scrambled_dir = '../params_results_exp_2/scrambled/top_1536/ClusterBasedWCSelector_201/1179/batch_size_96/training_data_scrambled/iter_{}.csv'\n",
    "\n",
    "orig_sum = 0\n",
    "scrambled_sum = 0\n",
    "for i in range(7):\n",
    "    orig_df = pd.read_csv(orig_dir.format(i))\n",
    "    scrambled_df = pd.read_csv(scrambled_dir.format(i))\n",
    "    \n",
    "    orig_sum += orig_df[task_name].sum()\n",
    "    scrambled_sum += scrambled_df[task_name].sum()\n",
    "    print('iter_{}. Index equality: {}. Label equality: {}'.format(i, \n",
    "                                                                   scrambled_df[col_name].equals(orig_df[col_name]), \n",
    "                                                                   scrambled_df[task_name].equals(orig_df[task_name])))\n",
    "\n",
    "    if i > 0:\n",
    "        assert scrambled_df[col_name].equals(orig_df[col_name]) and not scrambled_df[task_name].equals(orig_df[task_name])\n",
    "\n",
    "    print('Orig sum: {}. Scrambled sum: {}.'.format(orig_sum, scrambled_sum))\n",
    "\n",
    "print('Orig Total Actives: {}. Scrambled Total Actives:{}'.format(orig_total_actives, scrambled_total_actives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiment 2 Part 2: How well does explorative strategies perform on  random uniform label set?\n",
    "\n",
    "- dataset label was changed to be from a uniform binary distribution. \n",
    "- strategy was fixed to: ClusterBasedWCSelector_201\n",
    "- once the strategy selects the next iteration, it is added to the training data with the SCRAMBLED labels. \n",
    "- this was done to check if the strategy performs better than random. It should not as there is no structure in the feature-to-labelling scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_0. Index equality: True. Label equality: True\n",
      "Orig sum: 1.0. Uniform sum: 1.0.\n",
      "iter_1. Index equality: True. Label equality: False\n",
      "Orig sum: 35.0. Uniform sum: 47.0.\n",
      "iter_2. Index equality: False. Label equality: False\n",
      "Orig sum: 77.0. Uniform sum: 89.0.\n",
      "iter_3. Index equality: False. Label equality: False\n",
      "Orig sum: 90.0. Uniform sum: 140.0.\n",
      "iter_4. Index equality: False. Label equality: False\n",
      "Orig sum: 110.0. Uniform sum: 196.0.\n",
      "iter_5. Index equality: False. Label equality: False\n",
      "Orig sum: 126.0. Uniform sum: 244.0.\n",
      "iter_6. Index equality: False. Label equality: False\n",
      "Orig sum: 137.0. Uniform sum: 296.0.\n",
      "Orig Total Actives: 487.0. Uniform Total Actives:200353\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "col_name = 'Index ID'\n",
    "task_name = 'pcba-aid624173'\n",
    "\n",
    "#df1 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96/unlabeled_*.csv')])\n",
    "#df2 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96_scrambled/unlabeled_*.csv')])\n",
    "\n",
    "#orig_total_actives = df1[task_name].sum()\n",
    "#scrambled_total_actives = df2[task_name].sum()\n",
    "\n",
    "#del df1, df2\n",
    "\n",
    "orig_dir = '../params_results_exp_2/original/1179/batch_size_96/training_data/iter_{}.csv'\n",
    "scrambled_dir = '../params_results_exp_2/scrambled/top_1536/ClusterBasedWCSelector_201/1179/batch_size_96/training_data_uniform/iter_{}.csv'\n",
    "\n",
    "orig_sum = 0\n",
    "scrambled_sum = 0\n",
    "for i in range(7):\n",
    "    orig_df = pd.read_csv(orig_dir.format(i))\n",
    "    scrambled_df = pd.read_csv(scrambled_dir.format(i))\n",
    "    \n",
    "    orig_sum += orig_df[task_name].sum()\n",
    "    scrambled_sum += scrambled_df[task_name].sum()\n",
    "    print('iter_{}. Index equality: {}. Label equality: {}'.format(i, \n",
    "                                                                   scrambled_df[col_name].equals(orig_df[col_name]), \n",
    "                                                                   scrambled_df[task_name].equals(orig_df[task_name])))\n",
    "\n",
    "    print('Orig sum: {}. Uniform sum: {}.'.format(orig_sum, scrambled_sum))\n",
    "\n",
    "print('Orig Total Actives: {}. Uniform Total Actives:{}'.format(orig_total_actives, scrambled_total_actives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiment 2 Part 3: How well does explorative strategies perform on a dataset with the same number of actives as a the true dataset (i.e. 487) but they are randomized to different cpds?\n",
    "\n",
    "- the location of actives in the true dataset was randomly moved to other cpds. \n",
    "- strategy was fixed to: ClusterBasedWCSelector_201\n",
    "- once the strategy selects the next iteration, it is added to the training data with the SCRAMBLED labels. \n",
    "- this was done to check if the strategy performs better than random. It should not as there is no structure in the feature-to-labelling scheme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_0. Index equality: True. Label equality: True\n",
      "Orig sum: 1.0. Randomized sum: 1.0.\n",
      "iter_1. Index equality: True. Label equality: False\n",
      "Orig sum: 35.0. Randomized sum: 1.0.\n",
      "iter_2. Index equality: False. Label equality: False\n",
      "Orig sum: 77.0. Randomized sum: 1.0.\n",
      "iter_3. Index equality: False. Label equality: False\n",
      "Orig sum: 90.0. Randomized sum: 1.0.\n",
      "iter_4. Index equality: False. Label equality: False\n",
      "Orig sum: 110.0. Randomized sum: 1.0.\n",
      "iter_5. Index equality: False. Label equality: False\n",
      "Orig sum: 126.0. Randomized sum: 1.0.\n",
      "iter_6. Index equality: False. Label equality: False\n",
      "Orig sum: 137.0. Randomized sum: 1.0.\n",
      "Orig Total Actives: 487.0. Randomized Total Actives:487\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "col_name = 'Index ID'\n",
    "task_name = 'pcba-aid624173'\n",
    "\n",
    "df1 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96/unlabeled_*.csv')])\n",
    "df2 = pd.concat([pd.read_csv(x) for x in glob.glob('../datasets/aid624173_cv_96_randomize_actives/unlabeled_*.csv')])\n",
    "\n",
    "orig_total_actives = df1[task_name].sum()\n",
    "rand_total_actives = df2[task_name].sum()\n",
    "\n",
    "del df1, df2\n",
    "\n",
    "orig_dir = '../params_results_exp_2/original/1179/batch_size_96/training_data/iter_{}.csv'\n",
    "scrambled_dir = '../params_results_exp_2/scrambled/top_1536/ClusterBasedWCSelector_201/1179/batch_size_96/training_data_randomized_actives/iter_{}.csv'\n",
    "\n",
    "orig_sum = 0\n",
    "rand_sum = 0\n",
    "for i in range(7):\n",
    "    orig_df = pd.read_csv(orig_dir.format(i))\n",
    "    rand_df = pd.read_csv(scrambled_dir.format(i))\n",
    "    \n",
    "    orig_sum += orig_df[task_name].sum()\n",
    "    rand_sum += rand_df[task_name].sum()\n",
    "    print('iter_{}. Index equality: {}. Label equality: {}'.format(i, \n",
    "                                                                   rand_df[col_name].equals(orig_df[col_name]), \n",
    "                                                                   rand_df[task_name].equals(orig_df[task_name])))\n",
    "\n",
    "    print('Orig sum: {}. Randomized sum: {}.'.format(orig_sum, rand_sum))\n",
    "\n",
    "print('Orig Total Actives: {}. Randomized Total Actives:{}'.format(orig_total_actives, rand_total_actives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "col_name = 'Index ID'\n",
    "task_name = 'pcba-aid624173'\n",
    "odir = '../datasets/aid624173_cv_96/unlabeled_{}.csv'\n",
    "new_dir = '../datasets/aid624173_cv_96_randomize_actives/unlabeled_{}.csv'\n",
    "ofiles = glob.glob(odir.format('*'))\n",
    "\n",
    "total_actives = sum([pd.read_csv(x)[task_name].sum() for x in ofiles])\n",
    "\n",
    "actives_locations = np.random.choice(np.arange(len(ofiles)), size=int(total_actives), replace=False)\n",
    "\n",
    "for i in range(len(ofiles)):\n",
    "    of = odir.format(i)\n",
    "    nf = new_dir.format(i)\n",
    "    \n",
    "    odf = pd.read_csv(of)\n",
    "    odf[task_name] = 0\n",
    "    \n",
    "    if i in actives_locations:\n",
    "        random_idx = np.random.choice(odf.shape[0], size=1, replace=False)[0]\n",
    "        odf.loc[random_idx, task_name] = 1\n",
    "    \n",
    "    odf.to_csv(nf, index=False)\n",
    "    \n",
    "    assert pd.read_csv(nf)[col_name].equals(pd.read_csv(of)[col_name]) and not pd.read_csv(of)[task_name].equals(pd.read_csv(nf)[task_name])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
