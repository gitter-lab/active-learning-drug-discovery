{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed Jobs via Held Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "new_ram_reqs = 8\n",
    "jobs_log_file = './jobs.log'\n",
    "dag_file = './aldd_dag.dag'\n",
    "rnd_job_name_fmt='RND_{}_{}_{}'\n",
    "dist_job_name_fmt='DIST_{}_{}_{}'\n",
    "exploration_strategy = ['weighted', 'random', 'dissimilar']\n",
    "rnd_flag = '--random_param_sampling'\n",
    "dist_flag = '--no-random_param_sampling'\n",
    "\n",
    "with open(jobs_log_file) as f:\n",
    "    jobs_log = f.readlines()\n",
    "jobs_log = [x.strip() for x in jobs_log] \n",
    "jobs_log = jobs_log[1:]\n",
    "\n",
    "with open(dag_file) as f:\n",
    "    dag_log = f.readlines()\n",
    "dag_log = [x.strip() for x in dag_log] \n",
    "\n",
    "job_names_1 = []\n",
    "for i, x in enumerate(jobs_log):\n",
    "    job_split = jobs_log[i].split()\n",
    "    process_num = job_split[13]\n",
    "    batch_size_index = job_split[14]\n",
    "    exploration_strategy = job_split[11]\n",
    "    sampling_type = job_split[16]\n",
    "    \n",
    "    if rnd_flag == sampling_type:\n",
    "        job_names_1.append(rnd_job_name_fmt.format(process_num, batch_size_index, exploration_strategy))\n",
    "    else:\n",
    "        job_names_1.append(dist_job_name_fmt.format(process_num, batch_size_index, exploration_strategy))\n",
    "\n",
    "new_dag_log = []\n",
    "for i in range(len(job_names_1)):\n",
    "    new_dag_job_entry = [x for x in dag_log if job_names_1[i] in x]\n",
    "    vars_idx, vars_entry = [(xi, x) for xi, x in enumerate(new_dag_job_entry) if 'VARS {}'.format(job_names_1[i]) in x][0]\n",
    "    vars_entry_split = vars_entry.split()\n",
    "    vars_entry_split[-2] = 'ramreqs=\\\"{}\\\"'.format(new_ram_reqs)\n",
    "    vars_entry = ' '.join(vars_entry_split)\n",
    "    new_dag_job_entry[vars_idx] = vars_entry\n",
    "    new_dag_log.extend(new_dag_job_entry)\n",
    "    \n",
    "new_dag_log.extend(['RETRY ALL_NODES 5', 'CONFIG my.dag.config'])\n",
    "\n",
    "with open('aldd_dag_1.dag', 'w') as f:\n",
    "    for item in new_dag_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Failed Jobs via ./params_results success_flag.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "rnd_job_name_fmt='RND_{}_{}_{}'\n",
    "dist_job_name_fmt='DIST_{}_{}_{}'\n",
    "exploration_strategy = ['weighted', 'random', 'dissimilar']\n",
    "batch_size_index_dict = {96: 0, 384: 1, 1536: 2}\n",
    "\n",
    "job_names_2 = []\n",
    "params_dir = './params_results/*/*/*/*/'\n",
    "for d in glob.glob(params_dir):\n",
    "    sampling_type, exploration_strategy, process_num, batch_size_index = d.split('\\\\')[1:-1]\n",
    "    batch_size_index = batch_size_index_dict[int(batch_size_index[11:])]\n",
    "    process_num = int(process_num[23:])\n",
    "    \n",
    "    with open(d+'success_flag.txt') as f:\n",
    "        success_flag = int(f.readlines()[0][0])\n",
    "    \n",
    "    if not success_flag:\n",
    "        if sampling_type == 'random':\n",
    "            job_names_2.append(rnd_job_name_fmt.format(process_num, batch_size_index, exploration_strategy))\n",
    "        else:\n",
    "            job_names_2.append(dist_job_name_fmt.format(process_num, batch_size_index, exploration_strategy))\n",
    "            \n",
    "dag_file = './aldd_dag.dag'\n",
    "with open(dag_file) as f:\n",
    "    dag_log = f.readlines()\n",
    "dag_log = [x.strip() for x in dag_log] \n",
    "\n",
    "new_dag_log = []\n",
    "for i in range(len(job_names_1)):\n",
    "    new_dag_job_entry = [x for x in dag_log if job_names_1[i] in x]\n",
    "    vars_idx, vars_entry = [(xi, x) for xi, x in enumerate(new_dag_job_entry) if 'VARS {}'.format(job_names_1[i]) in x][0]\n",
    "    vars_entry_split = vars_entry.split()\n",
    "    vars_entry_split[-2] = 'ramreqs=\\\"{}\\\"'.format(new_ram_reqs)\n",
    "    vars_entry = ' '.join(vars_entry_split)\n",
    "    new_dag_job_entry[vars_idx] = vars_entry\n",
    "    new_dag_log.extend(new_dag_job_entry)\n",
    "    \n",
    "new_dag_log.extend(['RETRY ALL_NODES 5', 'CONFIG my.dag.config'])\n",
    "\n",
    "with open('aldd_dag_1.dag', 'w') as f:\n",
    "    for item in new_dag_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([98088, 43063, 47077,  3336, 37254, 55901, 22899, 30816, 25349, 73503, 36375, 13116,\n",
    " 24855, 15314, 30516, 500,  5826, 55496, 32248, 90093, 28205, 55373, 68909, 46852,\n",
    " 81062, 84905, 64208, 81894, 43486, 70805, 89341, 44552, 63467,  2317,  4545, 29547,\n",
    " 24713, 47398,  8739, 36044, 17506, 91962, 15909, 42747, 23978, 17977, 87044,  9420,\n",
    " 39870, 51334, 71180, 32812, 88466, 36281 , 9384,  8733, 64197, 23493, 84220, 28561,\n",
    " 61239, 40146, 74714,  4327, 85404, 91523, 88544, 61333, 72157, 67816,  3322, 55167,\n",
    " 81592,  4989, 65881, 86224, 37589, 35410, 82455, 35475,  8656, 13181, 22910, 44652,\n",
    " 75992, 35960, 38015, 63649, 41833, 16405, 65276, 87714,  2910, 29051, 56044, 53101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98088])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a >= 94761]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94857"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "94761 + 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append((1,))\n",
    "a[-1] = a[-1] + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.concat([pd.read_csv('../datasets/lc_clusters_cv_96/unlabeled_{}.csv'.format(i)) for i in range(1, 989)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([50412], dtype=int64),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df['Cluster_0.4'] == 108254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47676"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98088 - 50412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
