{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "dag_file = './aldd_dag_hs_0.dag'\n",
    "rnd_job_name_fmt='RND_{}_{}_{}'\n",
    "dist_job_name_fmt='DIST_{}_{}_{}'\n",
    "exploration_strategy = ['weighted', 'random', 'dissimilar']\n",
    "rnd_flag = '--random_param_sampling'\n",
    "dist_flag = '--no-random_param_sampling'\n",
    "\n",
    "\n",
    "with open(dag_file) as f:\n",
    "    dag_log = f.readlines()\n",
    "dag_log = [x.strip() for x in dag_log] \n",
    "\n",
    "new_dag_log = []\n",
    "for f in failed_jobs:\n",
    "    dist_type = f.split('_')[0]\n",
    "    process_num = int(f.split('_')[-1])\n",
    "    \n",
    "    job_name = 'RND_{}'.format(process_num)\n",
    "    if dist_type == 'distributive':\n",
    "        job_name = 'DIST_{}'.format(process_num)\n",
    "    new_dag_log.extend([x for x in dag_log if job_name in x])\n",
    "new_dag_log.extend(dag_log[-2:])\n",
    "\n",
    "with open('aldd_dag_f1.dag', 'w') as f:\n",
    "    for item in new_dag_log:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('../params_results/distributive/weighted/ClusterBasedWCSelector_488/batch_size_96/iter_*/exploration.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Check for duplicate selected cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "explore_files = glob.glob('../../../aldd_results/params_results/*/*/*/*/iter_*/exploration.csv')\n",
    "exploit_files = glob.glob('../../../aldd_results/params_results/*/*/*/*/iter_*/exploitation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e_file in enumerate(explore_files):\n",
    "    clear_output()\n",
    "    print('{}/{}'.format(i, len(explore_files)))\n",
    "    sel_df = pd.read_csv(e_file)\n",
    "    assert sel_df.shape[0] == sel_df['Index ID'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827/4828\n"
     ]
    }
   ],
   "source": [
    "for i, e_file in enumerate(exploit_files):\n",
    "    clear_output()\n",
    "    print('{}/{}'.format(i, len(exploit_files)))\n",
    "    sel_df = pd.read_csv(e_file)\n",
    "    assert sel_df.shape[0] == sel_df['Index ID'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_list = [[], [], []]\n",
    "failed_jobs = []\n",
    "all_jobs = []\n",
    "for i, s_file in enumerate(summary_files):\n",
    "    clear_output()\n",
    "    print('{}/{}'.format(i, len(summary_files)))\n",
    "    s_params = s_file.split('\\\\')\n",
    "    config_file = s_file.replace('summary.csv', 'config.csv')\n",
    "    dist_type = s_params[1]\n",
    "    exploration_strategy = s_params[2]\n",
    "    hs_name = s_params[3]\n",
    "    batch_size = s_params[4]\n",
    "    \n",
    "    hs_info = [dist_type, exploration_strategy, hs_name, batch_size, config_file]\n",
    "    hs_id = '{}_{}_{}_{}'.format(dist_type, exploration_strategy, hs_name, batch_size)\n",
    "    \n",
    "    all_jobs.append(hs_id)\n",
    "    \n",
    "    if pd.read_csv(config_file)['']\n",
    "    \n",
    "    df = pd.read_csv(s_file, index_col=0)\n",
    "    bsize_df = df[['exploitation_batch_size', 'exploration_batch_size']]\n",
    "    exploit_df = df[[m for m in df.columns if 'exploitation_hits_at_' in m]].sum(axis=1).to_frame(name='exploitation_hits')\n",
    "    explore_df = df[[m for m in df.columns if 'exploration_hits_at_' in m]].sum(axis=1).to_frame(name='exploration_hits')\n",
    "    exploit_max_df = df[[m for m in df.columns if 'exploitation_max_hits_at_' in m]].sum(axis=1).to_frame(name='exploitation_max_hits')\n",
    "    explore_max_df = df[[m for m in df.columns if 'exploration_max_hits_at_' in m]].sum(axis=1).to_frame(name='exploration_max_hits')\n",
    "    \n",
    "    sum_df = pd.concat([bsize_df, exploit_df, exploit_max_df, explore_df, explore_max_df], axis=1)\n",
    "    sum_df['total_batch_size'] = sum_df['exploitation_batch_size'] + sum_df['exploration_batch_size']\n",
    "    sum_df['total_hits'] = sum_df['exploitation_hits'] + sum_df['exploration_hits']\n",
    "    sum_df['total_max_hits'] = sum_df['exploitation_max_hits'] + sum_df['exploration_max_hits']\n",
    "    sum_df['total_max_hits'] = sum_df['total_max_hits'].apply((lambda x: min(x, int(batch_size.split('_')[-1]))))\n",
    "    \n",
    "    sum_df.iloc[-1,:] = sum_df.iloc[:-1,:].sum(axis=0)\n",
    "    sum_df['iteration'] = list(range(10)) + [9999]\n",
    "    sum_df['hyperparameter_id'] = hs_id\n",
    "    sum_df.index = list(range(10)) + ['total']\n",
    "    \n",
    "    sum_df['config_file'] = config_file\n",
    "    \n",
    "    if batch_size == 'batch_size_96':\n",
    "        res_df_list[0].append(sum_df)\n",
    "    elif batch_size == 'batch_size_384':\n",
    "        res_df_list[1].append(sum_df)\n",
    "    else:\n",
    "        res_df_list[2].append(sum_df)\n",
    "\n",
    "all_0 = pd.concat(res_df_list[0])\n",
    "all_1 = pd.concat(res_df_list[1])\n",
    "all_2 = pd.concat(res_df_list[2])\n",
    "all_0['hits_to_batch_size_ratio'] = all_0['total_hits'] / all_0['total_batch_size']\n",
    "all_1['hits_to_batch_size_ratio'] = all_1['total_hits'] / all_1['total_batch_size']\n",
    "all_2['hits_to_batch_size_ratio'] = all_2['total_hits'] / all_2['total_batch_size']\n",
    "all_df = pd.concat([all_0, all_1, all_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "a = glob.glob('../params_results/benchmark/InstanceBasedDissimilar/3605/batch_size_96/training_data/*.csv')\n",
    "df = pd.concat([pd.read_csv(x) for x in a])\n",
    "df['Index ID'].unique().shape[0] == (11*96), df['pcba-aid624173'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "hparams_dir='../../active-learning-drug-discovery/param_configs/experiment_2_hyperparams/*/*.json'\n",
    "    \n",
    "hparams_files = glob.glob(hparams_dir)\n",
    "hparams_files = [hp_file.replace('\\\\', '/') for hp_file in hparams_files]\n",
    "hparams_files = [hp_file.replace('../../active-learning-drug-discovery/', '../') for hp_file in hparams_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../param_configs/experiment_2_hyperparams/benchmarks/ClusterBasedRandom.json',\n",
       " '../param_configs/experiment_2_hyperparams/benchmarks/InstanceBasedDissimilar.json',\n",
       " '../param_configs/experiment_2_hyperparams/benchmarks/InstanceBasedRandom.json',\n",
       " '../param_configs/experiment_2_hyperparams/benchmarks/MABSelector_2.json',\n",
       " '../param_configs/experiment_2_hyperparams/benchmarks/MABSelector_3.json',\n",
       " '../param_configs/experiment_2_hyperparams/benchmarks/MABSelector_exploitive.json',\n",
       " '../param_configs/experiment_2_hyperparams/custom_cbws/ClusterBasedWCSelector_custom_1.json',\n",
       " '../param_configs/experiment_2_hyperparams/custom_cbws/ClusterBasedWCSelector_custom_2.json',\n",
       " '../param_configs/experiment_2_hyperparams/custom_cbws/InstanceBasedWCSelector_custom_0.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_201.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_341.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_368.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_396.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_411.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_467.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_55.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_581.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_590.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_609.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_625.json',\n",
       " '../param_configs/experiment_2_hyperparams/sampled_hyparams/ClusterBasedWCSelector_678.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./params_results/benchmarks/ClusterBasedRandom/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
